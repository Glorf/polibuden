{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cw-3izxQ2Lic"
   },
   "source": [
    "* Pobieramy dane,  wytrenowane modele, wektory oraz słowniki\n",
    "* Importujemy biblioteki (torch, nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "colab_type": "code",
    "id": "fuYF3cSN_frn",
    "outputId": "677a3496-9c2d-4af1-c7fc-d6d3343c8003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-02 19:15:52--  https://pjn-project.s3.eu-central-1.amazonaws.com/model-77000.pth\n",
      "Resolving pjn-project.s3.eu-central-1.amazonaws.com (pjn-project.s3.eu-central-1.amazonaws.com)... 52.219.74.112\n",
      "Connecting to pjn-project.s3.eu-central-1.amazonaws.com (pjn-project.s3.eu-central-1.amazonaws.com)|52.219.74.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 55465971 (53M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘model-77000.pth.1’\n",
      "\n",
      "\r",
      "model-77000.pth.1     0%[                    ]       0  --.-KB/s               \r",
      "model-77000.pth.1    17%[==>                 ]   9.51M  47.5MB/s               \r",
      "model-77000.pth.1    46%[========>           ]  24.57M  54.7MB/s               \r",
      "model-77000.pth.1    77%[==============>     ]  40.96M  60.1MB/s               \r",
      "model-77000.pth.1   100%[===================>]  52.90M  68.3MB/s    in 0.8s    \n",
      "\n",
      "2019-06-02 19:15:53 (68.3 MB/s) - ‘model-77000.pth.1’ saved [55465971/55465971]\n",
      "\n",
      "--2019-06-02 19:15:55--  https://pjn-project.s3.eu-central-1.amazonaws.com/rnn_vocabulary.pickle\n",
      "Resolving pjn-project.s3.eu-central-1.amazonaws.com (pjn-project.s3.eu-central-1.amazonaws.com)... 52.219.74.112\n",
      "Connecting to pjn-project.s3.eu-central-1.amazonaws.com (pjn-project.s3.eu-central-1.amazonaws.com)|52.219.74.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2276673 (2.2M) [binary/octet-stream]\n",
      "Saving to: ‘rnn_vocabulary.pickle.1’\n",
      "\n",
      "rnn_vocabulary.pick 100%[===================>]   2.17M  13.5MB/s    in 0.2s    \n",
      "\n",
      "2019-06-02 19:15:56 (13.5 MB/s) - ‘rnn_vocabulary.pickle.1’ saved [2276673/2276673]\n",
      "\n",
      "--2019-06-02 19:15:59--  https://pjn-project.s3.eu-central-1.amazonaws.com/word2vec.gensim\n",
      "Resolving pjn-project.s3.eu-central-1.amazonaws.com (pjn-project.s3.eu-central-1.amazonaws.com)... 52.219.74.21\n",
      "Connecting to pjn-project.s3.eu-central-1.amazonaws.com (pjn-project.s3.eu-central-1.amazonaws.com)|52.219.74.21|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68035918 (65M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘word2vec.gensim.1’\n",
      "\n",
      "word2vec.gensim.1   100%[===================>]  64.88M  46.6MB/s    in 1.4s    \n",
      "\n",
      "2019-06-02 19:16:00 (46.6 MB/s) - ‘word2vec.gensim.1’ saved [68035918/68035918]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pjn-project.s3.eu-central-1.amazonaws.com/model-77000.pth\n",
    "!wget https://pjn-project.s3.eu-central-1.amazonaws.com/rnn_vocabulary.pickle\n",
    "!wget https://pjn-project.s3.eu-central-1.amazonaws.com/word2vec.gensim\n",
    "!wget https://pjn-project.s3.eu-central-1.amazonaws.com/classifier-250.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "hf8YCbr6Abgd",
    "outputId": "356de289-333a-4e36-f023-b84d72f64e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BM5k8oW02H1b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-df753e5b0b15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "int_to_vocab = {}\n",
    "with open('rnn_vocabulary.pickle', 'rb') as f:\n",
    "  int_to_vocab = pickle.load(f)\n",
    "n_vocab = len(int_to_vocab)\n",
    "\n",
    "checkpoint_lm = torch.load('model-77000.pth')\n",
    "checkpoint_clas = torch.load('classifier-250.pth')\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7g0BSVN97zCQ"
   },
   "source": [
    "* Importujemy model języka - generator przepisów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAeZD93778tw"
   },
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "  def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "    super(RNNModule, self).__init__()\n",
    "    self.seq_size = seq_size\n",
    "    self.lstm_size = lstm_size\n",
    "    self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "    self.lstm = nn.LSTM(embedding_size, lstm_size, batch_first=True)\n",
    "    self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "  def forward(self, x, prev_state):\n",
    "    embed = self.embedding(x)\n",
    "    output, state = self.lstm(embed, prev_state)\n",
    "    logits = self.dense(output)\n",
    "\n",
    "    return logits, state\n",
    "    \n",
    "  def zero_state(self, batch_size):\n",
    "    return (torch.zeros(1, batch_size, self.lstm_size), torch.zeros(1, batch_size, self.lstm_size))\n",
    "\n",
    "net = RNNModule(n_vocab, 32, 64, 64)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(checkpoint_lm)\n",
    "\n",
    "\n",
    "def predict(device, net, int_to_vocab, top_k=5):\n",
    "  net.eval()\n",
    "    \n",
    "  words = ['<START>']\n",
    "  \n",
    "  vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "\n",
    "  result = []\n",
    "  state_h, state_c = net.zero_state(1)\n",
    "  state_h = state_h.to(device)\n",
    "  state_c = state_c.to(device)\n",
    "  for w in words:\n",
    "    result.append(w)\n",
    "    ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "    output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "  _, top_ix = torch.topk(output[0], k=top_k)\n",
    "  choices = top_ix.tolist()\n",
    "  choice = np.random.choice(choices[0])\n",
    "\n",
    "  result.append(int_to_vocab[choice])\n",
    "    \n",
    "  for _ in range(100):\n",
    "    ix = torch.tensor([[choice]]).to(device)\n",
    "    output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "    result.append(int_to_vocab[choice])\n",
    "    if int_to_vocab[choice] == '<END>':\n",
    "      break\n",
    "\n",
    "  print(' '.join(result).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmRg_K-G_9UD"
   },
   "source": [
    "* Importujemy model word2vec oraz funkcje pomocnicze dla tytułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBIL6hpjAFW4"
   },
   "outputs": [],
   "source": [
    "custom_stopwords = ['quick','healthy','good','worlds','best','recipe','cool','easy','tasty','fast','wonderful',' and ',' with ',' in ',' for ',' over ','w/',' n ',' s ']\n",
    "porter = PorterStemmer()\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "model_word2vec = gensim.models.Word2Vec.load('word2vec.gensim')\n",
    "\n",
    "def parse_title(title):\n",
    "  res = title.lower()\n",
    "  res = re.sub('[^a-z ]+', ' ',res)\n",
    "  words = nltk.word_tokenize(res) \n",
    "  res = ''\n",
    "  for w in words:\n",
    "    if w not in stopwords.words('english'):\n",
    "        res = res + ' ' + w\n",
    "  for i in custom_stopwords:\n",
    "    res = res.replace(i, ' ')\n",
    "  res = re.sub('[ ]+', ' ',res)\n",
    "  res = re.sub('^[ ]+', '',res)\n",
    "  res = re.sub('[ ]+$', '',res)\n",
    "  res = porter.stem(res)\n",
    "  res = word_tokenize(res)\n",
    "  return res\n",
    "\n",
    "def calc_title_vector(words, model):\n",
    "  words = parse_title(words)\n",
    "  res = np.zeros((100, ))\n",
    "  for word in words:\n",
    "    if word in model:\n",
    "      res += model[word]\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEWBasAJBT0d"
   },
   "source": [
    "* Importujemy model oraz funkcje pomocnicze dla generatora listy składników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Cf33xT6BeOq",
    "outputId": "d0c6722c-ff1b-4d6c-b753-911d3865911f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-74e2bdeee520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                'yogurt', 'vodka', 'pork', 'soy', 'tomato', 'cinnamon', 'raspberry', 'banana', 'chili']\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mIngredientClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIngredientClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "ingredients_full = ['salt', 'peper', 'sugar', 'oil', 'onion', 'butter', 'egg', 'garlic', 'flour', 'olive', \n",
    "               'water', 'milk', 'tomate', 'lemon', 'vanilla', 'bean', 'parsley', 'wine', 'potato', 'beef', \n",
    "               'rice', 'orange', 'soda', 'mustard', 'parmesan', 'bread', 'mushroom', 'lime', 'chicken', 'basil',\n",
    "               'cheese', 'juice', 'chocolate', 'candies', 'cream', 'honey', 'apple', 'pepper', 'strawberry', \n",
    "               'yogurt', 'vodka', 'pork', 'soy', 'tomato', 'cinnamon', 'raspberry', 'banana', 'chili']\n",
    "\n",
    "class IngredientClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(IngredientClassifier, self).__init__()\n",
    "    self.layer = torch.nn.Sequential(\n",
    "      nn.Linear(100, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, len(ingredients_full)),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer(torch.tensor(x).to(device).float())\n",
    "    return x\n",
    "      \n",
    "net_clas = IngredientClassifier().to(device)\n",
    "net_clas.load_state_dict(checkpoint_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "sQAjHy3fo5_5",
    "outputId": "f08877e8-2b62-4650-850b-03a792af58ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4809, 0.4440, 0.4937, 0.4745, 0.4605, 0.4981, 0.4810, 0.4528, 0.4815,\n",
       "        0.4826, 0.4942, 0.4729, 0.4638, 0.4904, 0.4772, 0.4541, 0.4400, 0.4938,\n",
       "        0.4672, 0.4680, 0.4818, 0.4475, 0.4387, 0.4821, 0.4817, 0.4684, 0.4465,\n",
       "        0.4656, 0.4733, 0.4722, 0.4691, 0.4545, 0.4479, 0.4617, 0.4480, 0.4684,\n",
       "        0.4701, 0.5186, 0.4448, 0.4443, 0.4773, 0.4375, 0.4458, 0.4757, 0.4682,\n",
       "        0.4846, 0.4727, 0.4713], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "Nazwa = \"roman salad\" #@param {type:\"string\"}\n",
    "result = net_clas(calc_title_vector(Nazwa, model_word2vec)).cpu().detach().numpy()\n",
    "\n",
    "r2 = []\n",
    "for res in range(0, len(ingredients_full)):\n",
    "  r2.append((ingredients_full[res], result[res]))\n",
    "  \n",
    "ingredients = [r[0] for r in sorted(r2, key=lambda k: k[1], reverse=True)[0:5]]\n",
    "ingredients\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PJN-prezentacja.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
